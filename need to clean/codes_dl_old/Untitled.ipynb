{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good luck\n",
      "load train....\n",
      "          app  device  os  channel  is_attributed  min  hour  ipcount  qty  \\\n",
      "8347993    12       1  32      124              0   38    23       99   99   \n",
      "33676443    9       1  20      334              0   27     7      385  385   \n",
      "26863117   18       1  13      134              0   11     5       27   27   \n",
      "33316878    2       1  13      122              0   20     7       55   55   \n",
      "4002018     2       1  47      477              0   31    18       54   54   \n",
      "\n",
      "          ip_app_count  ip_app_os_count  \n",
      "8347993            169                3  \n",
      "33676443           633               27  \n",
      "26863117            60                7  \n",
      "33316878           107               16  \n",
      "4002018             89               48  \n"
     ]
    }
   ],
   "source": [
    "# This kernel is based on Alexander Kireev's deep learning model:\n",
    "#   https://www.kaggle.com/alexanderkireev/deep-learning-support-imbalance-architect-9671\n",
    "# (See notes and references below.)\n",
    "# I (Andy Harless) have made the following changes:\n",
    "#   1. Add 2 more (narrower) layers on top\n",
    "#   2. Eliminate \"day\" and \"wday\" variables (no variation in this sample)\n",
    "#   3. Change target weight from 99 to 70\n",
    "#   4. Add batch normalization\n",
    "#   5. Only one epoch\n",
    "#   6. Eliminate weight decay\n",
    "#   7. Increase batch size\n",
    "#   8. Increase dropout\n",
    "\n",
    "# version 4:  adding ipcount\n",
    "\n",
    "\n",
    "# good day, my friends\n",
    "# in this kernel we try to continue development of our DL models\n",
    "# =================================================================================================\n",
    "# we continue our work\n",
    "# this kernel is attempt to configure neural network for work with imbalanced data (see ~150th row)\n",
    "# =================================================================================================\n",
    "# thanks for people who share his works. i hope together we can create smth interest\n",
    "\n",
    "# https://www.kaggle.com/baomengjiao/embedding-with-neural-network\n",
    "# https://www.kaggle.com/gpradk/keras-starter-nn-with-embeddings\n",
    "# https://www.kaggle.com/pranav84/lightgbm-fixing-unbalanced-data-auc-0-9787\n",
    "# https://www.kaggle.com/rteja1113/lightgbm-with-count-features\n",
    "# https://www.kaggle.com/knowledgegrappler/a-simple-nn-solution-with-keras-0-48611-pl\n",
    "# https://www.kaggle.com/isaienkov/rnn-with-keras-ridge-sgdr-0-43553\n",
    "# https://www.kaggle.com/valkling/mercari-rnn-2ridge-models-with-notes-0-42755/versions#base=2202774&new=2519287\n",
    "\n",
    "print ('Good luck')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "import gc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# import libs\n",
    "import numpy as np \n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "path = '../input/'\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }\n",
    "\n",
    "\n",
    "print('load train....')\n",
    "# we save only day 9\n",
    "train_set_name = 'train_0'\n",
    "train_df_full = pd.read_pickle(train_set_name)\n",
    "train_df_full, train_df_del = train_test_split(train_df_full, test_size=0.8)\n",
    "del train_df_del\n",
    "gc.collect()\n",
    "\n",
    "print(train_df_full.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required ML packages\n",
    "from sklearn.linear_model import LogisticRegression #logistic regression\n",
    "from sklearn import svm #support vector Machine\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN\n",
    "from sklearn.naive_bayes import GaussianNB #Naive bayes\n",
    "from sklearn.tree import DecisionTreeClassifier #Decision Tree\n",
    "from sklearn.neural_network import MLPClassifier #Neural Network\n",
    "from sklearn.model_selection import train_test_split #training and testing data split\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import confusion_matrix #for confusion matrix\n",
    "\n",
    "# plot consufion matrix definition\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    fig=plt.gcf()\n",
    "    fig.set_size_inches(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=train_test_split(train_df_full,test_size=0.3,random_state=0,stratify=train_df_full['is_attributed'])\n",
    "\n",
    "train_X=train.drop(['is_attributed'], axis=1)\n",
    "train_Y=train[['is_attributed']]\n",
    "test_X=test.drop(['is_attributed'], axis=1)\n",
    "test_Y=test[['is_attributed']]\n",
    "X=train_df_full.drop(['is_attributed'], axis=1)\n",
    "Y=train_df_full['is_attributed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          app  device  os  channel  min  hour  ipcount   qty  ip_app_count  \\\n",
      "46630400   18       1  19      107   44    11       82    82           118   \n",
      "40248103   64       1  41      459   44     9       17    17            25   \n",
      "33959912   12       1  13      265   33     7       69    69           144   \n",
      "46389536    5       1  19      377   39    11     1456  1456            62   \n",
      "2871566    15       1  19      480   22    17      110   110          1157   \n",
      "\n",
      "          ip_app_os_count  \n",
      "46630400               20  \n",
      "40248103                1  \n",
      "33959912               24  \n",
      "46389536               18  \n",
      "2871566               349  \n",
      "          is_attributed\n",
      "46630400              0\n",
      "40248103              0\n",
      "33959912              0\n",
      "46389536              0\n",
      "2871566               1\n",
      "          app  device   os  channel  min  hour  ipcount  qty  ip_app_count  \\\n",
      "54409442   13       1   13      477   12    14      137  137            40   \n",
      "8928946     5       1   35      377   51    23       18   18             2   \n",
      "37303894   33    3032  607      347   44     8       15   15             1   \n",
      "31135464   23       1   14      153   35     6      101  101            33   \n",
      "20727232    3       1    6      115   26     3       95   95           227   \n",
      "\n",
      "          ip_app_os_count  \n",
      "54409442                9  \n",
      "8928946                 1  \n",
      "37303894                1  \n",
      "31135464                2  \n",
      "20727232               35  \n",
      "          is_attributed\n",
      "54409442              0\n",
      "8928946               0\n",
      "37303894              0\n",
      "31135464              0\n",
      "20727232              0\n"
     ]
    }
   ],
   "source": [
    "print(train_X.head())\n",
    "print(train_Y.head())\n",
    "print(test_X.head())\n",
    "print(test_Y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel='rbf', C=1, gamma=0.1)\n",
    "model.fit(train_X, train_Y) \n",
    "prediction1=model.predict(test_X)\n",
    "print('Accuracy for rbf SVM is ',metrics.accuracy_score(prediction1,test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=svm.SVC(kernel='linear',C=0.1,gamma=0.1)\n",
    "model.fit(train_X,train_Y)\n",
    "prediction2=model.predict(test_X)\n",
    "print('Accuracy for linear SVM is',metrics.accuracy_score(prediction2,test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DecisionTreeClassifier()\n",
    "model.fit(train_X,train_Y)\n",
    "prediction5=model.predict(test_X)\n",
    "print('The accuracy of the Decision Tree is',metrics.accuracy_score(prediction5,test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KNeighborsClassifier() \n",
    "model.fit(train_X,train_Y)\n",
    "prediction6=model.predict(test_X)\n",
    "print('The accuracy of the KNN is',metrics.accuracy_score(prediction6,test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=100)\n",
    "model.fit(train_X,train_Y)\n",
    "prediction8=model.predict(test_X)\n",
    "print('The accuracy of the Random Forests is',metrics.accuracy_score(prediction8,test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['is_attributed'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('load test...')\n",
    "train_set_name = 'test'\n",
    "test_df = pd.read_pickle(train_set_name)\n",
    "print(test_df.head())\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['click_id'] = test_df['click_id'].astype('int')\n",
    "\n",
    "def get_keras_data(dataset):\n",
    "    X = {\n",
    "        'app': np.array(dataset.app),\n",
    "        'ch': np.array(dataset.channel),\n",
    "        'dev': np.array(dataset.device),\n",
    "        'os': np.array(dataset.os),\n",
    "        'h': np.array(dataset.hour),\n",
    "        'qty': np.array(dataset.qty),\n",
    "        'ipcount': np.array(dataset.ipcount),\n",
    "        'c1': np.array(dataset.ip_app_count),\n",
    "        'c2': np.array(dataset.ip_app_os_count)\n",
    "    }\n",
    "    return X\n",
    "\n",
    "test_df = get_keras_data(test_df)\n",
    "\n",
    "print(\"predicting....\")\n",
    "# sub['is_attributed'] = \n",
    "del test_df; gc.collect()\n",
    "print(sub.head())\n",
    "print(\"writing....\")\n",
    "sub.to_csv('tddlakah1.csv', index=False, float_format='%.3f')\n",
    "print(\"done...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
