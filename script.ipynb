{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "First of all, thanks to the work of: \n",
    "\n",
    "Md Asraful Kabir\n",
    "https://www.kaggle.com/asraful70/talkingdata-added-new-features-in-lightgbm\n",
    "\n",
    "This kernel is made for running NOT on this environment. If you run it locally, you will get a result of 0.9811\n",
    "\n",
    "At the moment I'm lucky, to use the server of TU Berlin. So if you like to download and submit it, please go ahead.\n",
    "\n",
    "Any ideas on improvement are welcome. \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILENO= 200102 #To distinguish the output file name.\n",
    "debug=0  #Whethere or not in debuging mode\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "path = '... add your path...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5d5f4586-9384-46c1-8ec5-b230836b60b4",
    "_uuid": "5f70048bd5d231d90f674e2d0dde787fc2ec6a34",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### Feature extraction ######\n",
    "\n",
    "#### Extracting next click feature \n",
    "    ### Taken help from https://www.kaggle.com/nanomathias/feature-engineering-importance-testing\n",
    "    ###Did some Cosmetic changes \n",
    "\n",
    "predictors=[]\n",
    "def do_next_Click( df,agg_suffix='nextClick', agg_type='float32'):\n",
    "    \n",
    "    print(f\">> \\nExtracting {agg_suffix} time calculation features...\\n\")\n",
    "    \n",
    "    GROUP_BY_NEXT_CLICKS = [\n",
    "    \n",
    "    # V1\n",
    "    # {'groupby': ['ip']},\n",
    "    # {'groupby': ['ip', 'app']},\n",
    "    # {'groupby': ['ip', 'channel']},\n",
    "    # {'groupby': ['ip', 'os']},\n",
    "    \n",
    "    # V3\n",
    "    {'groupby': ['ip', 'app', 'device', 'os', 'channel']},\n",
    "    {'groupby': ['ip', 'os', 'device']},\n",
    "    {'groupby': ['ip', 'os', 'device', 'app']},\n",
    "    {'groupby': ['ip', 'os', 'device', 'channel']},\n",
    "    \n",
    "    {'groupby': ['ip', 'os', 'device', 'app', 'hour']},\n",
    "    {'groupby': ['ip', 'os', 'device', 'channel', 'hour']},\n",
    "    {'groupby': ['device']},\n",
    "    {'groupby': ['device', 'channel']},     \n",
    "    {'groupby': ['app', 'device', 'channel']},\n",
    "    {'groupby': ['device', 'hour']}\n",
    "    ]\n",
    "\n",
    "    # Calculate the time to next click for each group\n",
    "    for spec in GROUP_BY_NEXT_CLICKS:\n",
    "    \n",
    "       # Name of new feature\n",
    "        new_feature = '{}_{}'.format('_'.join(spec['groupby']),agg_suffix)    \n",
    "    \n",
    "        # Unique list of features to select\n",
    "        all_features = spec['groupby'] + ['click_time']\n",
    "\n",
    "        # Run calculation\n",
    "        print(f\">> Grouping by {spec['groupby']}, and saving time to {agg_suffix} in: {new_feature}\")\n",
    "        df[new_feature] = (df[all_features].groupby(spec[\n",
    "            'groupby']).click_time.shift(-1) - df.click_time).dt.seconds.astype(agg_type)\n",
    "        \n",
    "        predictors.append(new_feature)\n",
    "        gc.collect()\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5b648809-8547-485c-afa1-ca8c1589d82a",
    "_uuid": "38c831c7e214f42b6ae9ed920e93afc035d6c5b3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_prev_Click( df,agg_suffix='prevClick', agg_type='float32'):\n",
    "\n",
    "    print(f\">> \\nExtracting {agg_suffix} time calculation features...\\n\")\n",
    "    \n",
    "    GROUP_BY_NEXT_CLICKS = [\n",
    "    \n",
    "    # V1\n",
    "    # {'groupby': ['ip']},\n",
    "    # {'groupby': ['ip', 'app']},\n",
    "    {'groupby': ['ip', 'channel']},\n",
    "    # {'groupby': ['ip', 'os']},\n",
    "    \n",
    "    # V3\n",
    "    #{'groupby': ['ip', 'app', 'device', 'os', 'channel']},\n",
    "    #{'groupby': ['ip', 'os', 'device']},\n",
    "    #{'groupby': ['ip', 'os', 'device', 'app']}\n",
    "    ]\n",
    "\n",
    "    # Calculate the time to next click for each group\n",
    "    for spec in GROUP_BY_NEXT_CLICKS:\n",
    "    \n",
    "       # Name of new feature\n",
    "        new_feature = '{}_{}'.format('_'.join(spec['groupby']),agg_suffix)    \n",
    "    \n",
    "        # Unique list of features to select\n",
    "        all_features = spec['groupby'] + ['click_time']\n",
    "\n",
    "        # Run calculation\n",
    "        print(f\">> Grouping by {spec['groupby']}, and saving time to {agg_suffix} in: {new_feature}\")\n",
    "        df[new_feature] = (df.click_time - df[all_features].groupby(spec[\n",
    "                'groupby']).click_time.shift(+1) ).dt.seconds.astype(agg_type)\n",
    "        \n",
    "        predictors.append(new_feature)\n",
    "        gc.collect()\n",
    "    return (df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f4c42c53-7475-42a0-8ade-bf959ede26c3",
    "_uuid": "ef5d9449e31c1899638b2981d2f5d2c1b8dfccd9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Below a function is written to extract count feature by aggregating different cols\n",
    "def do_count( df, group_cols, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    agg_name='{}count'.format('_'.join(group_cols))  \n",
    "    if show_agg:\n",
    "        print( \"\\nAggregating by \", group_cols ,  '... and saved in', agg_name )\n",
    "    gp = df[group_cols][group_cols].groupby(group_cols).size().rename(agg_name).to_frame().reset_index()\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    predictors.append(agg_name)\n",
    "#     print('predictors',predictors)\n",
    "    gc.collect()\n",
    "    return( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "02b11371-2459-4404-87c1-bce3cf72bd0b",
    "_uuid": "4bc3d9f10443b34a13d8714b6c1964d1a3716f2d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##  Below a function is written to extract unique count feature from different cols\n",
    "def do_countuniq( df, group_cols, counted, agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    agg_name= '{}_by_{}_countuniq'.format(('_'.join(group_cols)),(counted))  \n",
    "    if show_agg:\n",
    "        print( \"\\nCounting unqiue \", counted, \" by \", group_cols ,  '... and saved in', agg_name )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].nunique().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    predictors.append(agg_name)\n",
    "#     print('predictors',predictors)\n",
    "    gc.collect()\n",
    "    return( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3c482f38-b1b9-48de-a579-804395224d06",
    "_uuid": "48b7a210d3efa605385b5ad358a8c8779b9a3581",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Below a function is written to extract cumulative count feature  from different cols    \n",
    "def do_cumcount( df, group_cols, counted,agg_type='uint32', show_max=False, show_agg=True ):\n",
    "    agg_name= '{}_by_{}_cumcount'.format(('_'.join(group_cols)),(counted)) \n",
    "    if show_agg:\n",
    "        print( \"\\nCumulative count by \", group_cols , '... and saved in', agg_name  )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].cumcount()\n",
    "    df[agg_name]=gp.values\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    predictors.append(agg_name)\n",
    "#     print('predictors',predictors)\n",
    "    gc.collect()\n",
    "    return( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "13afe749-74bb-43ed-8e17-55d2bba97a25",
    "_uuid": "3243aabbd5542a9738d18cdda4623c2ceeb46b25",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Below a function is written to extract mean feature  from different cols\n",
    "def do_mean( df, group_cols, counted, agg_type='float32', show_max=False, show_agg=True ):\n",
    "    agg_name= '{}_by_{}_mean'.format(('_'.join(group_cols)),(counted))  \n",
    "    if show_agg:\n",
    "        print( \"\\nCalculating mean of \", counted, \" by \", group_cols , '... and saved in', agg_name )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].mean().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    predictors.append(agg_name)\n",
    "#     print('predictors',predictors)\n",
    "    gc.collect()\n",
    "    return( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8b972eb2-257a-4665-b545-41feec4fec84",
    "_uuid": "58391ba221f1ba39e209f1a27a64a3f31639b194",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_var( df, group_cols, counted, agg_type='float32', show_max=False, show_agg=True ):\n",
    "    agg_name= '{}_by_{}_var'.format(('_'.join(group_cols)),(counted)) \n",
    "    if show_agg:\n",
    "        print( \"\\nCalculating variance of \", counted, \" by \", group_cols , '... and saved in', agg_name )\n",
    "    gp = df[group_cols+[counted]].groupby(group_cols)[counted].var().reset_index().rename(columns={counted:agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    if show_max:\n",
    "        print( agg_name + \" max value = \", df[agg_name].max() )\n",
    "    df[agg_name] = df[agg_name].astype(agg_type)\n",
    "    predictors.append(agg_name)\n",
    "#     print('predictors',predictors)\n",
    "    gc.collect()\n",
    "    return( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "817f7531-51e5-4fdd-a775-1e7db136d5cc",
    "_uuid": "1947e5661d2f263e4624192b62e69175e8eef459",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###  A function is written to train the lightGBM model with different given parameters\n",
    "if debug:\n",
    "    print('*** debug parameter set: this is a test run for debugging purposes ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a766b7db-9326-4f42-ad55-d7073189ade5",
    "_uuid": "4781bdbcfd494d8d6f3917e6ca69d3a0ea901f7f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def lgb_modelfit_nocv(params, dtrain, dvalid, predictors, target='target', objective='binary', metrics='auc',\n",
    "                 feval=None, early_stopping_rounds=50, num_boost_round=3000, verbose_eval=10, categorical_features=None):\n",
    "    lgb_params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': objective,\n",
    "        'metric':metrics,\n",
    "        'learning_rate': 0.05,\n",
    "        #'is_unbalance': 'true',  #because training data is unbalance (replaced with scale_pos_weight)\n",
    "        'num_leaves': 31,  # we should let it be smaller than 2^(max_depth)\n",
    "        'max_depth': -1,  # -1 means no limit\n",
    "        'min_child_samples': 20,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "        'max_bin': 255,  # Number of bucketed bin for feature values\n",
    "        'subsample': 0.6,  # Subsample ratio of the training instance.\n",
    "        'subsample_freq': 0,  # frequence of subsample, <=0 means no enable\n",
    "        'colsample_bytree': 0.3,  # Subsample ratio of columns when constructing each tree.\n",
    "        'min_child_weight': 5,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "        'subsample_for_bin': 200000,  # Number of samples for constructing bin\n",
    "        'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "        'reg_alpha': 0,  # L1 regularization term on weights\n",
    "        'reg_lambda': 0,  # L2 regularization term on weights\n",
    "        'nthread': 8,\n",
    "        'verbose': 0,\n",
    "    }\n",
    "    \n",
    "    lgb_params.update(params)\n",
    "\n",
    "    print(\"preparing validation datasets\")\n",
    "\n",
    "    xgtrain = lgb.Dataset(dtrain[predictors].values, label=dtrain[target].values,\n",
    "                          feature_name=predictors,\n",
    "                          categorical_feature=categorical_features\n",
    "                          )\n",
    "    xgvalid = lgb.Dataset(dvalid[predictors].values, label=dvalid[target].values,\n",
    "                          feature_name=predictors,\n",
    "                          categorical_feature=categorical_features\n",
    "                          )\n",
    "\n",
    "    evals_results = {}\n",
    "\n",
    "    bst1 = lgb.train(lgb_params, \n",
    "                     xgtrain, \n",
    "                     valid_sets=[xgtrain, xgvalid], \n",
    "                     valid_names=['train','valid'], \n",
    "                     evals_result=evals_results, \n",
    "                     num_boost_round=num_boost_round,\n",
    "                     early_stopping_rounds=early_stopping_rounds,\n",
    "                     verbose_eval=10, \n",
    "                     feval=feval)\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"bst1.best_iteration: \", bst1.best_iteration)\n",
    "    print(metrics+\":\", evals_results['valid'][metrics][bst1.best_iteration-1])\n",
    "\n",
    "    return (bst1,bst1.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d35c3ed1-8688-4abb-83ff-dd5b5e4f9946",
    "_uuid": "5f825831f9747074654c122cb8aa951b454ed699",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Running the full calculation.\n",
    "\n",
    "#### A function is written here to run the full calculation with defined parameters.\n",
    "\n",
    "def DO(frm,to,fileno):\n",
    "    dtypes = {\n",
    "            'ip'            : 'uint32',\n",
    "            'app'           : 'uint16',\n",
    "            'device'        : 'uint8',\n",
    "            'os'            : 'uint16',\n",
    "            'channel'       : 'uint16',\n",
    "            'click_time'    : 'str',\n",
    "            'is_attributed' : 'uint8',\n",
    "            'click_id'      : 'uint32'\n",
    "            }\n",
    "\n",
    "    print('loading train data...',frm,to)\n",
    "    train_df = pd.read_csv(path + \"train.csv\", parse_dates=['click_time'], skiprows=range(1,frm), nrows=to-frm, dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'is_attributed'])\n",
    "\n",
    "    print('loading test data...')\n",
    "    if debug:\n",
    "        test_df = pd.read_csv(path +  \"test_supplement.csv\", nrows=100000, parse_dates=['click_time'], dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "    else:\n",
    "        test_df = pd.read_csv(path + \"test_supplement.csv\", parse_dates=['click_time'], dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "\n",
    "        \n",
    "    len_train = len(train_df)\n",
    "    train_df = train_df.append(test_df)\n",
    "    \n",
    "    del test_df\n",
    "    \n",
    "    train_df['click_time'] = pd.to_datetime(train_df['click_time'])\n",
    "    train_df['hour'] = pd.to_datetime(train_df.click_time).dt.hour.astype('int8')\n",
    "    train_df['day'] = pd.to_datetime(train_df.click_time).dt.day.astype('int8')     \n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    train_df = do_next_Click( train_df,agg_suffix='nextClick', agg_type='float32'  ); gc.collect()\n",
    "    train_df = do_prev_Click( train_df,agg_suffix='prevClick', agg_type='float32'  ); gc.collect()  \n",
    "    train_df = do_countuniq( train_df, ['ip'], 'channel' ); gc.collect()\n",
    "    \n",
    "    train_df = do_countuniq( train_df, ['ip', 'device', 'os'], 'app'); gc.collect()\n",
    "    train_df = do_mean( train_df, ['ip', 'device', 'os'], 'app'); gc.collect()\n",
    "    \n",
    "    train_df = do_countuniq( train_df, ['ip', 'day'], 'hour' ); gc.collect()\n",
    "    train_df = do_countuniq( train_df, ['ip'], 'app'); gc.collect()\n",
    "    train_df = do_countuniq( train_df, ['ip', 'app'], 'os'); gc.collect()\n",
    "    train_df = do_countuniq( train_df, ['ip'], 'device'); gc.collect()\n",
    "    train_df = do_countuniq( train_df, ['app'], 'channel'); gc.collect()\n",
    "    train_df = do_cumcount( train_df, ['ip'], 'os'); gc.collect()\n",
    "    train_df = do_cumcount( train_df, ['ip', 'device', 'os'], 'app'); gc.collect()\n",
    "    train_df = do_count( train_df, ['ip', 'day', 'hour'] ); gc.collect()\n",
    "    train_df = do_count( train_df, ['ip', 'app']); gc.collect()\n",
    "    train_df = do_count( train_df, ['ip', 'app', 'os']); gc.collect()\n",
    "    train_df = do_var( train_df, ['ip', 'day', 'channel'], 'hour'); gc.collect()\n",
    "    train_df = do_var( train_df, ['ip', 'app', 'os'], 'hour'); gc.collect()\n",
    "    train_df = do_var( train_df, ['ip', 'app', 'channel'], 'day'); gc.collect()\n",
    "    train_df = do_mean( train_df, ['ip', 'app', 'channel'], 'hour' ); gc.collect()\n",
    "    \n",
    "    train_df = do_mean( train_df, ['os', 'device', 'app', 'channel'], 'hour' ); gc.collect()\n",
    "    train_df = do_countuniq( train_df, ['os', 'device', 'app', 'channel'], 'hour' ); gc.collect()\n",
    "    #train_df = do_var( train_df, ['os', 'device', 'app', 'channel'], 'hour' ); gc.collect()\n",
    "\n",
    "    \n",
    "    \n",
    "    print(train_df.head(5))\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    print('\\n\\nBefore appending predictors...\\n\\n',sorted(predictors))\n",
    "    target = 'is_attributed'\n",
    "    word= ['app','device','os', 'channel', 'hour']\n",
    "    for feature in word:\n",
    "        if feature not in predictors:\n",
    "            predictors.append(feature)\n",
    "    categorical = ['app', 'device', 'os', 'channel', 'hour', 'os_device_app_channel_by_hour_countuniq']\n",
    "    #categorical = ['app', 'device', 'os', 'channel', 'hour']\n",
    "\n",
    "    print('\\n\\nAfter appending predictors...\\n\\n',sorted(predictors))\n",
    "\n",
    "    test_df = train_df[len_train:]\n",
    "    val_df = train_df[(len_train-val_size):len_train]\n",
    "    train_df = train_df[:(len_train-val_size)]\n",
    "\n",
    "    print(\"\\ntrain size: \", len(train_df))\n",
    "    print(\"\\nvalid size: \", len(val_df))\n",
    "    print(\"\\ntest size : \", len(test_df))\n",
    "\n",
    "    sub = pd.DataFrame()\n",
    "    sub['click_id'] = test_df['click_id'].astype('int')\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"Training...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': 0.10,\n",
    "        #'is_unbalance': 'true', # replaced with scale_pos_weight argument\n",
    "        'num_leaves': 7,  # 2^max_depth - 1\n",
    "        'max_depth': 3,  # -1 means no limit\n",
    "        'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "        'max_bin': 100,  # Number of bucketed bin for feature values\n",
    "        'subsample': 0.7,  # Subsample ratio of the training instance.\n",
    "        'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n",
    "        'colsample_bytree': 0.9,  # Subsample ratio of columns when constructing each tree.\n",
    "        'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "        'scale_pos_weight':200 # because training data is extremely unbalanced \n",
    "\n",
    "    }\n",
    "    (bst,best_iteration) = lgb_modelfit_nocv(params, \n",
    "                            train_df, \n",
    "                            val_df, \n",
    "                            predictors, \n",
    "                            target, \n",
    "                            objective='binary', \n",
    "                            metrics='auc',\n",
    "                            early_stopping_rounds=30, \n",
    "                            verbose_eval=True, \n",
    "                            num_boost_round=1000, \n",
    "                            categorical_features=categorical)\n",
    "\n",
    "    print('[{}]: model training time'.format(time.time() - start_time))\n",
    "    del train_df\n",
    "    del val_df\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    ax = lgb.plot_importance(bst, max_num_features=300)\n",
    "    \n",
    "    plt.savefig('test%d.png'%(fileno), dpi=600,bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print(\"Features importance...\")\n",
    "    gain = bst.feature_importance('gain')\n",
    "    ft = pd.DataFrame({'feature':bst.feature_name(), 'split':bst.feature_importance('split'), 'gain':100 * gain / gain.sum()}).sort_values('gain', ascending=False)\n",
    "    print(ft)    \n",
    "    \n",
    "\n",
    "    ##############################################\n",
    "    print('loading test data...')\n",
    "    if debug:\n",
    "        dfTest = pd.read_csv(path +  \"test.csv\", nrows=100000, parse_dates=['click_time'], dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "    else:\n",
    "        dfTest = pd.read_csv(path + \"test.csv\", parse_dates=['click_time'], dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'click_id'])\n",
    "    \n",
    "    ip_dfTest_supplement = pd.DataFrame()\n",
    "    ip_dfTest_supplement['ip'] = test_df['ip']\n",
    "    ip_dfTest_supplement['app'] = test_df['app']\n",
    "    ip_dfTest_supplement['device'] = test_df['device']\n",
    "    ip_dfTest_supplement['os'] = test_df['os']\n",
    "    ip_dfTest_supplement['channel'] = test_df['channel']\n",
    "    ip_dfTest_supplement['click_time'] = test_df['click_time']\n",
    "\n",
    "    print(\"Predicting...\")\n",
    "    ip_dfTest_supplement['is_attributed'] = bst.predict(test_df[predictors],num_iteration=best_iteration)\n",
    "    \n",
    "    del test_df\n",
    "    \n",
    "    ip_dfTest_supplement = ip_dfTest_supplement.groupby(['ip',\n",
    "                                                    'app',\n",
    "                                                    'device',\n",
    "                                                    'os',\n",
    "                                                    'channel',\n",
    "                                                    'click_time'])['is_attributed'].agg(['mean']).reset_index().rename(index=str, \n",
    "                                                        columns=({'ip': 'ip',\n",
    "                                                                  'mean': 'is_attributed'}))\n",
    "    print(ip_dfTest_supplement.columns)\n",
    "    \n",
    "    sub = pd.DataFrame()\n",
    "    sub = dfTest.merge(ip_dfTest_supplement, how='left',on=['ip','app', 'device', 'os', 'channel','click_time'])\n",
    "    \n",
    "    print(len(sub))\n",
    "    print(sub.columns)\n",
    "    del dfTest\n",
    "    del ip_dfTest_supplement\n",
    "    \n",
    "    \n",
    "    print(\"del ip,app,device,os,channel,click_weekday\")\n",
    "    del sub['ip']\n",
    "    del sub['app']\n",
    "    del sub['device']\n",
    "    del sub['os']\n",
    "    del sub['channel']\n",
    "    del sub['click_time']\n",
    "\n",
    "    print(len(sub))\n",
    "    print(sub.head(5))\n",
    "    \n",
    "    ##############################################\n",
    "\n",
    "    sub.to_csv('sub_it%d.csv'%(fileno),index=False,float_format='%.9f')\n",
    "    print(\"done...\")\n",
    "    return sub\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3d4f4a9d-88c2-4874-b142-60aa58465956",
    "_uuid": "6e1c57f368e2e7c31f47e4ab5cd1ed20a38a85ae",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### Chunk size defining and final run  ############\n",
    "'''\n",
    "nrows=184903891-1\n",
    "nchunk=25000000\n",
    "#val_size=2500000\n",
    "val_size=5000000\n",
    "\n",
    "\n",
    "#frm=nrows-65000000\n",
    "frm=0\n",
    "to=nrows\n",
    "if debug:\n",
    "    frm=0\n",
    "    nchunk=100000\n",
    "    val_size=10000\n",
    "    to=frm+nchunk\n",
    "\n",
    "\n",
    "sub=DO(frm,to,FILENO)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "ea0f2dd128e8666e8708d4ff38d17d501bd54062"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "df1 = pd.read_csv('../input/sub-it200102csv/sub_it200102.csv')\n",
    "print(len(df1))\n",
    "df1.to_csv('sub-it200102csv', index=False, float_format='%.9f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ac2095e7ab0bf7ccffaadeb37ed2462376372da",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
